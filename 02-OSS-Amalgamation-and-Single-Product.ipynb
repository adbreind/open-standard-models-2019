{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open-Source Amalgamation and Single-Product Formats\n",
    "\n",
    "## Amalgamation\n",
    "\n",
    "The simplest form of export is \"amalgamation\" ... in which case the model and all necessary code to run are emitted as one big chunk.\n",
    "\n",
    "In some cases, it's a single source code file that can be compiled on nearly any platform as a standalone program.\n",
    "  * Classic amalgamation: MXNet + model code https://mxnet.incubator.apache.org/faq/smart_device.html#amalgamation-making-the-whole-system-a-single-file\n",
    "\n",
    "In other cases, it's a chunk of consumable IR code that can be consumed in a common runtime:\n",
    "  * H2O POJO export https://github.com/h2oai/h2o-3/blob/master/h2o-docs/src/product/productionizing.rst#pojo-quick-start\n",
    "  * \"Python Lambda Format\" -- i.e., any single-function-call wrapper around a heap of Python + Python-compatible dependecies\n",
    "    * *I'm not making this up* (not to say there's no role for this approach, but unlikely in the enterprise ML inference setting)\n",
    "    * Examples\n",
    "      * AWS Lambda, Google Cloud Functions, Azure Functions\n",
    "      * https://fission.io/\n",
    "      * http://fnproject.io/\n",
    "      * https://github.com/kubeless/kubeless\n",
    "      * http://openwhisk.incubator.apache.org/\n",
    "      * etc.\n",
    "    \n",
    "And sometimes ... it's a coder implementing a model by hand and compiling it! (For simple, popular models, like linear/logistic regression, it's pretty easy once you have the model params.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Does this Look Like? Let's Try It...\n",
    "\n",
    "First, we need a model. So we'll train a quick linear regression on R's Diamonds dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/diamonds.csv')\n",
    "\n",
    "X = data.carat\n",
    "y = data.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression().fit(X.values.reshape(-1,1), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a basic model for predicting price (in dollars) from weight (in carats).\n",
    "\n",
    "The params are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7756.42561797]), -2256.360580045403)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_, model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a standalone (\"amalgamated\") version of this model using [SKompiler](https://pypi.org/project/SKompiler/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT 7756.425617968435 * x1 + -2256.360580045403 AS y \\nFROM data'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skompiler import skompile\n",
    "\n",
    "expr = skompile(model.predict)\n",
    "expr.to('sqlalchemy/postgresql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y = 7756.4256179684353*x[0] - 2256.3605800454029;'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr.to('sympy/c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a quick example with a decision tree. First, we'll create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model_tree = DecisionTreeRegressor(max_depth=4).fit(X.values.reshape(-1,1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if (x[0] <= 0.99500000476837158) {\n",
      "   if (x[0] <= 0.625) {\n",
      "      if (x[0] <= 0.45499999821186066) {\n",
      "         if (x[0] <= 0.375) {\n",
      "            y = 703.12009314703926;\n",
      "         }\n",
      "         else {\n",
      "            y = 961.50142450142448;\n",
      "         }\n",
      "      }\n",
      "      else {\n",
      "         if (x[0] <= 0.50499999523162842) {\n",
      "            y = 1449.1314668289715;\n",
      "         }\n",
      "         else {\n",
      "            y = 1738.4445772843724;\n",
      "         }\n",
      "      }\n",
      "   }\n",
      "   else {\n",
      "      if (x[0] <= 0.86500000953674316) {\n",
      "         if (x[0] <= 0.72500002384185791) {\n",
      "            y = 2567.4392059553352;\n",
      "         }\n",
      "         else {\n",
      "            y = 2945.0985116938341;\n",
      "         }\n",
      "      }\n",
      "      else {\n",
      "         if (x[0] <= 0.89499998092651367) {\n",
      "            y = 3355.3200000000002;\n",
      "         }\n",
      "         else {\n",
      "            y = 3954.4697792254797;\n",
      "         }\n",
      "      }\n",
      "   }\n",
      "}\n",
      "else {\n",
      "   if (x[0] <= 1.4950000047683716) {\n",
      "      if (x[0] <= 1.1749999523162842) {\n",
      "         if (x[0] <= 1.0349999666213989) {\n",
      "            y = 5450.4928928159816;\n",
      "         }\n",
      "         else {\n",
      "            y = 5976.9871222076217;\n",
      "         }\n",
      "      }\n",
      "      else {\n",
      "         if (x[0] <= 1.2949999570846558) {\n",
      "            y = 6967.0990896358544;\n",
      "         }\n",
      "         else {\n",
      "            y = 8067.174321503132;\n",
      "         }\n",
      "      }\n",
      "   }\n",
      "   else {\n",
      "      if (x[0] <= 1.9149999618530273) {\n",
      "         if (x[0] <= 1.6649999618530273) {\n",
      "            y = 10551.598714416896;\n",
      "         }\n",
      "         else {\n",
      "            y = 12211.204081632653;\n",
      "         }\n",
      "      }\n",
      "      else {\n",
      "         if (x[0] <= 2.0049999952316284) {\n",
      "            y = 14088.291525423729;\n",
      "         }\n",
      "         else {\n",
      "            y = 14951.250397035468;\n",
      "         }\n",
      "      }\n",
      "   }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for line in skompile(model_tree.predict).to('sympy/c').split('\\n'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pros and Cons: Amalgamation\n",
    "\n",
    "Pros:\n",
    "* Easy-to-understand concept\n",
    "* Fairly portable\n",
    "* Can be compact and performant\n",
    "  * May be a good choice for extremely constrained embedded environments\n",
    "\n",
    "Cons:\n",
    "* Not interoperable with other high-level environments\n",
    "* Violates separation of code (logic) from data (parameters)\n",
    "* May not fit in well with enterprise manageability and operations needs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open-Source Single-Product Format(s)\n",
    "\n",
    "I.e., a format which serves a specific product ecosystem, but is not intended to interoperate with other systems nor serve as a \"standard\"\n",
    "\n",
    "*Examples:*\n",
    "\n",
    "__SparkML + MLeap__\n",
    "  * MLeap supports Spark, some scikit-learn models and some TensorFlow models\n",
    "  * Represents models in a \"MLeap Bundle\"\n",
    "  * MLeap runtime is a JAR that can run in any Java application (or by with a lightweight scoring wrapper provided by MLeap)\n",
    "\n",
    "__TensorFlow + TensorFlow Serving__\n",
    "  * TensorFlow models (created directly with TensorFlow or with Keras) serialize to a TF-specific protocol buffer representation\n",
    "  * TensorFlow Serving loads the latest version of a model\n",
    "    * TF Serving exposes a gRPC service and a REST endpoint\n",
    "    \n",
    "Within the intended ecosystem, we can easily explort and use a model, but we don't get portability across tools/ecosystems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
